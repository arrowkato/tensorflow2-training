{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Platform でのトレーニングと推論\n",
    "\n",
    "このノートブックでは、TensorFlow 2.1 のモデルを GCP の AI Platform を使用してトレーニングと推論を実行する方法を学びます。\n",
    "\n",
    "AI Platform Training/Prediction はト ML モデルのトレーニングとデプロイを行うマネージドサービスです。 <br>\n",
    "インフラの用意やプロビジョニング、メンテナンスを行うことなく、シームレスに ML の環境を利用することができます。\n",
    "\n",
    "## 目的\n",
    "- TensorFlow 2系を用いたモデルの作り方を学習する\n",
    "- AI Platform Training を利用して、クラウド上での分散学習を行う方法を学習する\n",
    "- AI Platform Prediction を利用して、オートスケールする推論環境へのデプロイと推論の実行方法を学ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, subprocess\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \",tf.version.VERSION)\n",
    "\n",
    "cmd = 'gcloud config list project --format \"value(core.project)\"'\n",
    "PROJECT = subprocess.Popen(\n",
    "      cmd, stdout=subprocess.PIPE,\n",
    "      shell=True, universal_newlines=True).stdout.readlines()[0].rstrip('\\n')\n",
    "print(\"Your current GCP Project Name is: {}\".format(PROJECT))\n",
    "REGION = \"us-central1\" # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "BUCKET = \"{}-keras\".format(PROJECT)\n",
    "\n",
    "# Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"BUCKET\"] = BUCKET # DEFAULT BUCKET WILL BE <PROJECT ID>-keras\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # SET TF ERROR LOG VERBOSITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python の trainer パッケージを作成する\n",
    "\n",
    "AI Platformのトレーニングに送信する `trainer` パッケージの作成をはじめましょう。\n",
    "\n",
    "AI Platform Training のトレーニングジョブを実行する際には、クラウド上での実行のためにコードをまとめ上げてクラウドに送られます。<br>\n",
    "そのために、コードは Python のパッケージにまとめられる必要があります。\n",
    "\n",
    "Python のパッケージは、一つ以上の `.py` ファイルと、ディレクトリがパッケージであることを示すために `__init__.py` ファイルを含める必要があります。<br>\n",
    "`__init__.py` は 初期実行を含めることもできますが、今回は必要ありませんので空のファイルとしておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Remove files from previous notebook runs.\n",
    "rm -rf taxifare_tf2\n",
    "\n",
    "mkdir taxifare_tf2\n",
    "touch taxifare_tf2/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.py ファイルを作成する\n",
    "\n",
    "AI Platformに送信するファイルには、`__init__.py` 以外に二つの `.py` ファイルを含めます。<br>\n",
    "- `model.py`: Keras モデルの定義 \n",
    "- `task.py` : コマンドラインからの引数をパースし、`model.py` へ渡す実行ファイル\n",
    "\n",
    "ノートブックのセルを `%%writefile` マジックからはじめると、指定された名前のファイルへセルの内容を書き込みます。<br>\n",
    "`-a` フラグを追加すると、既に存在するファイルへ上書きを行います。<br>\n",
    "そのため、以下の`%%writefile`から始まるセルは、 **かならず一回のみの実行**としてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初に、必要なパッケージのインストールを行いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile taxifare_tf2/model.py\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# set TF error log verbosity\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは、すべてのデータ列名、予測するデータ列（ラベル）名、そしてデフォルトの値を定義しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a taxifare_tf2/model.py \n",
    "\n",
    "CSV_COLUMNS = [\n",
    "    'fare_amount',\n",
    "    'hourofday',\n",
    "    'dayofweek',\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude'\n",
    "]\n",
    "\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "\n",
    "DEFAULTS = [[0.0], [0], [0], [0.0], [0.0], [0.0], [0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、使用する特徴量と予測するラベルを定義し、トレーニング用データセットを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a taxifare_tf2/model.py \n",
    "\n",
    "def features_and_labels(row_data):\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "    return row_data, label  # features, label\n",
    "\n",
    "# load the training data\n",
    "def load_dataset(pattern, batch_size=1, mode=tf.estimator.ModeKeys.EVAL):\n",
    "    dataset = (tf.data.experimental.make_csv_dataset(pattern, batch_size, CSV_COLUMNS, DEFAULTS)\n",
    "               .map(features_and_labels) # features, label\n",
    "              )\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.prefetch(1) # take advantage of multi-threading; 1=AUTOTUNE\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、同様に DNN モデルを設計します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a taxifare_tf2/model.py \n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true))) \n",
    "\n",
    "def build_model():\n",
    "    INPUT_COLS = [\n",
    "    'hourofday',\n",
    "    'dayofweek',\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude',\n",
    "]\n",
    "\n",
    "    # input layer\n",
    "    inputs = {\n",
    "        colname : tf.keras.layers.Input(name=colname, shape=(), dtype='float32')\n",
    "           for colname in INPUT_COLS\n",
    "    }\n",
    "    feature_columns = {\n",
    "        colname : tf.feature_column.numeric_column(colname)\n",
    "           for colname in INPUT_COLS\n",
    "    }\n",
    "    \n",
    "    # the constructor for DenseFeatures takes a list of numeric columns\n",
    "    # The Functional API in Keras requires that you specify: LayerConstructor()(inputs)\n",
    "    dnn_inputs = tf.keras.layers.DenseFeatures(feature_columns.values())(inputs)\n",
    "\n",
    "    # two hidden layers of [32, 8] just in like the BQML DNN\n",
    "    h1 = tf.keras.layers.Dense(32, activation='relu', name='h1')(dnn_inputs)\n",
    "    h2 = tf.keras.layers.Dense(8, activation='relu', name='h2')(h1)\n",
    "\n",
    "    # final output is a linear activation because this is regression\n",
    "    output = tf.keras.layers.Dense(1, activation='linear', name='fare')(h2)\n",
    "    model = tf.keras.models.Model(inputs, output)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=[rmse, 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、トレーニングプロセスを管理する関数を作成します。<br>\n",
    "`args` の辞書は、 トレーニングの際に`task.py` を通してコマンドラインから渡されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a taxifare_tf2/model.py \n",
    "\n",
    "def train_and_export_model(args):\n",
    "    TRAIN_BATCH_SIZE = 128 \n",
    "    NUM_TRAIN_EXAMPLES = 50000 * args['train_epochs']\n",
    "    NUM_EVALS = args['train_epochs']\n",
    "    NUM_EVAL_EXAMPLES = 15000\n",
    "\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = build_model()\n",
    "\n",
    "    trainds = load_dataset(args['train_data_path'],\n",
    "                           TRAIN_BATCH_SIZE * 4,\n",
    "                           tf.estimator.ModeKeys.TRAIN)\n",
    "    evalds = load_dataset(args['eval_data_path'],\n",
    "                          1000,\n",
    "                          tf.estimator.ModeKeys.EVAL).take(NUM_EVAL_EXAMPLES//1000)\n",
    "\n",
    "    steps_per_epoch = NUM_TRAIN_EXAMPLES // (TRAIN_BATCH_SIZE * NUM_EVALS)\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=args['output_dir']),\n",
    "                tf.keras.callbacks.TensorBoard(args['output_dir'])]\n",
    "\n",
    "    history = model.fit(trainds,\n",
    "                        verbose=2,\n",
    "                        validation_data=evalds,\n",
    "                        epochs=NUM_EVALS,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `task.py` ファイルを作成する\n",
    "\n",
    "次に、 `task.py` ファイルを作成します<br>\n",
    "このファイルは、`model.py` の `train_and_export_model` 関数が使用するパラメータを、コマンドラインの引数を渡す役割を持ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile taxifare_tf2/task.py \n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from . import model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--train_data_path\",\n",
    "        help = \"GCS or local path to training data\",\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_epochs\",\n",
    "        help = \"Steps to run the training job for (default: 5)\",\n",
    "        type = int,\n",
    "        default = 5\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_data_path\",\n",
    "        help = \"GCS or local path to evaluation data\",\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help = \"GCS location to write checkpoints and export models\",\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--job-dir\",\n",
    "        help = \"This is not used by our model, but it is required by gcloud\",\n",
    "    )\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    model.train_and_export_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルをローカルでテストする\n",
    "\n",
    "AI Platform でトレーニングを行う前に、パッケージが動作するかどうかをローカルで確認しましょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./taxi_model\n",
    "!python3 -m taxifare_tf2.task \\\n",
    "    --train_data_path=../data/taxi-train.csv \\\n",
    "    --eval_data_path=../data/taxi-valid.csv \\\n",
    "    --train_epochs=3 \\\n",
    "    --output_dir=./local_taxi_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud AI Platform でトレーニングを実行する\n",
    "\n",
    "全てがローカルで動作することが確認できましたので、いよいよクラウドで実行しましょう。<br>\n",
    "まずは、トレーニングに使用するデータを GCS のバケットに移します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://takumi-keras/...\n",
      "ServiceException: 409 Bucket takumi-keras already exists.\n",
      "CommandException: No URLs matched\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb gs://{BUCKET}\n",
    "!gsutil -m cp -r ../data/ gs://{BUCKET}/taxifare_example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラウドにジョブを送信する際には、 [`gcloud ai-platform jobs submit training [ジョブ名]`](https://cloud.google.com/sdk/gcloud/reference/ml-engine/jobs/submit/training) を使用し、AI Platform に渡す追加のパラメータをいくつか指定します。\n",
    "- ジョブ名: ジョブに付けるユニークな識別子。実行時の時間を付けてユニークにするのが一般的。\n",
    "- package-path: GCS 上の Python パッケージのパス\n",
    "- runtime-version: 使用するTensorFlow のバージョン\n",
    "- python-version: 使用する Python のバージョン。現在は、 TF2.1 では Python 3.7 のみがサポートされています、\n",
    "- region: トレーニングを行うリージョン。AI Platform Training がサポートされているリージョンについては、[こちら](https://cloud.google.com/ml-engine/docs/tensorflow/regions) を参照してください。\n",
    "- scale-tier: トレーニングを行うインフラの構成。詳細は[こちら](https://cloud.google.com/ai-platform/training/docs/machine-types)を参照してください。\n",
    "\n",
    "パラメータ名の無い `-- \\` 以下には、 task.py に渡す引数を指定することができます、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"gs://{}/taxifare_example/saved_model/\".format(BUCKET)\n",
    "TRAIN_DATA_PATH = \"gs://{}/taxifare_example/data/taxi-train.csv\".format(BUCKET)\n",
    "EVAL_DATA_PATH = \"gs://{}/taxifare_example/data/taxi-valid.csv\".format(BUCKET)\n",
    "\n",
    "!gsutil -m rm -rf {OUTDIR} # start fresh each time\n",
    "!gcloud ai-platform jobs submit training taxifare_$(date -u +%y%m%d_%H%M%S) \\\n",
    "    --package-path=taxifare_tf2 \\\n",
    "    --module-name=taxifare_tf2.task \\\n",
    "    --job-dir=gs://{BUCKET}/taxifare_example \\\n",
    "    --python-version=3.7 \\\n",
    "    --runtime-version=2.1 \\\n",
    "    --region={REGION}\\\n",
    "    --scale-tier BASIC \\\n",
    "    -- \\\n",
    "    --train_data_path={TRAIN_DATA_PATH} \\\n",
    "    --eval_data_path={EVAL_DATA_PATH}  \\\n",
    "    --train_epochs=20 \\\n",
    "    --output_dir={OUTDIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard でトレーニングをモニタリングする\n",
    "\n",
    "以下の手順でTensorboard を実行してください。\n",
    "- 以下のセルを実行し、出力を Cloud Shell に貼り付けて実行\n",
    "- Cloud Shell 右上の Web Preview -> Preview on Port 8080 をクリック\n",
    "- Tensorboard を確認する（正しく表示されない場合は、しばらく待ち、ブラウザを更新してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tensorboard --logdir {} --port 8080'.format(OUTDIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングは 5-7 分ほどで完了します。<br>\n",
    "完了したら、以下のセルを実行し、 `SavedModel` が保存されていることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls -r {OUTDIR}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルをデプロイする\n",
    "\n",
    "では、エクスポートされた `SavedModel` をデプロイして、REST APIで呼び出せるようにしましょう。<br>\n",
    "そうすることによって、需要に応じてオートスケールする推論環境を使用することができます。\n",
    "\n",
    "AI Platform Prediction はバージョニング機能を持っています。<br>\n",
    "はじめにモデルフォルダを作成し、そのフォルダの中にモデルのバージョン (`v1`) を作成します。バージョンのデプロイには５分ほどの時間がかかります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION='v1'\n",
    "\n",
    "!gcloud ai-platform models create taxifare --regions us-central1\n",
    "!gcloud ai-platform versions create {VERSION} --model taxifare \\\n",
    "    --origin {OUTDIR} \\\n",
    "    --python-version=3.7 \\\n",
    "    --runtime-version 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the model creation at [GCP Console > AI Platform](https://console.cloud.google.com/mlengine/models/taxifare/) でモニタリングをし、モデルのバージョン (`v1`)が作られたら次に進んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを使って推論をするために、新しいデータを用意する必要があります。<br>\n",
    "では、午後6時に[ウォールストリートからブライアント公園まで](https://www.google.com/maps/dir/%E3%82%A6%E3%82%A9%E3%83%BC%E3%83%AB%E8%A1%97,+%E3%82%A2%E3%83%A1%E3%83%AA%E3%82%AB%E5%90%88%E8%A1%86%E5%9B%BD+New+York/Bryant+Park,+%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A8%E3%83%BC%E3%82%AF+%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A8%E3%83%BC%E3%82%AF%E5%B7%9E+%E3%82%A2%E3%83%A1%E3%83%AA%E3%82%AB%E5%90%88%E8%A1%86%E5%9B%BD/@40.7302283,-74.0247121,13z/data=!3m1!4b1!4m13!4m12!1m5!1m1!1s0x89c25a165bedccab:0x2cb2ddf003b5ae01!2m2!1d-74.0088256!2d40.7060361!1m5!1m1!1s0x89c259aae7a0b1bd:0xb49cafb82537f1a7!2m2!1d-73.9832326!2d40.7535965)の4マイルの距離をタクシー移動する際の料金を予測してみましょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build(\"ml\", \"v1\", credentials = credentials,\n",
    "            discoveryServiceUrl = \"https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json\")\n",
    "\n",
    "request_data = {\"instances\":\n",
    "  [\n",
    "      {\n",
    "        \"dayofweek\": 1,\n",
    "        \"hourofday\": 18,\n",
    "        \"pickup_longitude\": -73.0101638,\n",
    "        \"pickup_latitude\": 40.7059409,\n",
    "        \"dropoff_longitude\": -73.9834672,\n",
    "        \"dropoff_latitude\": 40.7532916,\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "\n",
    "parent = \"projects/{}/models/taxifare\".format(PROJECT) # use default version\n",
    "\n",
    "response = api.projects().predict(body = request_data, name = parent).execute()\n",
    "print(\"response = {0}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
