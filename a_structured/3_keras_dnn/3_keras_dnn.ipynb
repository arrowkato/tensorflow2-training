{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シンプルな DNN モデルを Keras で実装する\n",
    "\n",
    "このノートブックでは、 Keras のパイプラインで ML データセットを読み込み、その後 ニューヨークのタクシー乗車料金を予測する Keras の DNN モデルを実装します。\n",
    "\n",
    "### 目的\n",
    "1. `tf.data` を利用して CSV ファイルを読み込む方法を確認する\n",
    "2. DNN アーキテクチャの入力層、隠れ層、出力層を設計する\n",
    "3. DNN アーキテクチャを確認、可視化する\n",
    "4. モデルをローカルでトレーニングし、損失カーブを可視化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, subprocess\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \",tf.version.VERSION)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # SET TF ERROR LOG VERBOSITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV ファイルを指定する\n",
    "\n",
    "ここでは、最初のノートブックで作成したデータを読み込んでいきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ../data/*.csv\n",
    "!head ../data/taxi-train*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data を利用して CSV ファイルを読み込む\n",
    "\n",
    "`0_explore.ipynb` で作成したデータを仕様しましょう。このデータは `./data`内に格納されています。\n",
    "\n",
    "まずは、すべてのデータ列名、予測するデータ列（ラベル）名、そしてデフォルトの値を定義しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS  = ['fare_amount',\n",
    "            'dayofweek',\n",
    "            'hourofday',\n",
    "            'pickup_longitude',\n",
    "            'pickup_latitude',\n",
    "            'dropoff_longitude',\n",
    "            'dropoff_latitude',\n",
    "           ]\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS     = [[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、使用する特徴量と予測するラベルを定義し、トレーニング用データセットを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_labels(row_data):\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "    return row_data, label  # features, label\n",
    "\n",
    "# load the training data\n",
    "def load_dataset(pattern, batch_size=1, mode=tf.estimator.ModeKeys.EVAL):\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = tf.data.experimental.make_csv_dataset(pattern, batch_size, CSV_COLUMNS, DEFAULTS, num_epochs=None)\n",
    "    else:\n",
    "        dataset = tf.data.experimental.make_csv_dataset(pattern, batch_size, CSV_COLUMNS, DEFAULTS, num_epochs=1)\n",
    "        \n",
    "    dataset = dataset.map(features_and_labels).prefetch(1) # take advantage of multi-threading; 1=AUTOTUNE\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras で DNN モデルを作成する\n",
    "\n",
    "では、 Deep Neural Network (DNN) のモデルを Keras で実装し、入力層と隠れ層を指定しましょう。<br>\n",
    "そして DNN のアーキテクチャを出力、可視化してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a simple Keras DNN using its Functional API\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true))) \n",
    "\n",
    "def build_dnn_model():\n",
    "    INPUT_COLS = ['dayofweek',\n",
    "            'hourofday',\n",
    "            'pickup_longitude',\n",
    "            'pickup_latitude',\n",
    "            'dropoff_longitude',\n",
    "            'dropoff_latitude',\n",
    "           ]\n",
    "\n",
    "    # input layer\n",
    "    inputs = {\n",
    "        colname : tf.keras.layers.Input(name=colname, shape=(), dtype='float32')\n",
    "           for colname in INPUT_COLS\n",
    "    }\n",
    "    feature_columns = {\n",
    "        colname : tf.feature_column.numeric_column(colname)\n",
    "           for colname in INPUT_COLS\n",
    "    }\n",
    "    \n",
    "    # the constructor for DenseFeatures takes a list of numeric columns\n",
    "    # The Functional API in Keras requires that you specify: LayerConstructor()(inputs)\n",
    "    dnn_inputs = tf.keras.layers.DenseFeatures(feature_columns.values())(inputs)\n",
    "\n",
    "    # two hidden layers of [32, 8] just in like the BQML DNN\n",
    "    h1 = tf.keras.layers.Dense(32, activation='relu', name='h1')(dnn_inputs)\n",
    "    h2 = tf.keras.layers.Dense(8, activation='relu', name='h2')(h1)\n",
    "\n",
    "    # final output is a linear activation because this is regression\n",
    "    output = tf.keras.layers.Dense(1, activation='linear', name='fare')(h2)\n",
    "    model = tf.keras.models.Model(inputs, output)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=[rmse, 'mse'])\n",
    "    return model\n",
    "\n",
    "print(\"Here is our DNN architecture so far:\\n\")\n",
    "model = build_dnn_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN を可視化する\n",
    "\n",
    "Keras の [plot_model](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/utils/plot_model) 機能を利用して、 DNN を可視化してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, 'dnn_model.png', show_shapes=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルをトレーニングする\n",
    "\n",
    "モデルをトレーニングは、 [model.fit()](https://keras.io/models/model/#fit) を呼び出すだけで実行できます。\n",
    "\n",
    "NUM_TRAIN_EXAMPLES はより大きい数値を使用するべきでしょう。<br>\n",
    "小さいデータでのトレーニング/評価に基づいてモデルの質を推し量るのは限界があるためです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_TRAIN_EXAMPLES = 1000 * 5 # training dataset repeats, so it will wrap around\n",
    "NUM_EPOCH = 10  # how many times to evaluate\n",
    "\n",
    "trainds = load_dataset('../data/taxi-train*', BATCH_SIZE, tf.estimator.ModeKeys.TRAIN)\n",
    "evalds = load_dataset('../data/taxi-valid*', BATCH_SIZE, tf.estimator.ModeKeys.EVAL)\n",
    "\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // BATCH_SIZE \n",
    "\n",
    "history = model.fit(trainds, \n",
    "                    validation_data=evalds,\n",
    "                    epochs=NUM_EPOCH, \n",
    "                    steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの損失カーブを可視化する\n",
    "\n",
    "続いて、matplotlib を使用して、トレーニングと評価の損失カーブを可視化してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "for idx, key in enumerate(['loss', 'rmse']):\n",
    "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "    plt.plot(history.history[key])\n",
    "    plt.plot(history.history['val_{}'.format(key)])\n",
    "    plt.title('model {}'.format(key))\n",
    "    plt.ylabel(key)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを使った推論をローカルで実行する\n",
    "\n",
    "Keras を用いた推論は、 [model.predict()](https://keras.io/models/model/#predict) を呼び出し、特徴量を渡すことで実行することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しに、[ウォール街のチェイス銀行からブライアント公園までのルート](https://www.google.com/maps/dir/Chase+Bank,+45+Wall+St,+New+York,+NY+10005,+United+States/Bryant+Park,+New+York,+NY+10018,+United+States/data=!4m8!4m7!1m2!1m1!1s0x89c25a16d45a5027:0x215b141554f11385!1m2!1m1!1s0x89c259aae7a0b1bd:0xb49cafb82537f1a7!3e0?sa=X&ved=2ahUKEwjs9fnF8KzuAhUGE6YKHSQJDhcQ-A96BAgBEA4)の料金を調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict({\n",
    "    'pickup_longitude': tf.convert_to_tensor([-74.0098147]),\n",
    "    'pickup_latitude': tf.convert_to_tensor([40.7060502]),\n",
    "    'dropoff_longitude': tf.convert_to_tensor([-73.9833705]),\n",
    "    'dropoff_latitude': tf.convert_to_tensor([40.7532916]),\n",
    "    'hourofday': tf.convert_to_tensor([18.0]), \n",
    "    'dayofweek': tf.convert_to_tensor([1.0]), \n",
    "}, steps=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかし、もちろんこの方法は現実的ではありません。なぜなら、クライアントのメモリにモデルオブジェクトが置いてあることは稀だからです。<br>\n",
    "モデルをファイルにエクスポートし、クライアント側はそのファイルからモデルを使用できるように設定する必要があります。\n",
    "\n",
    "この機能については、次のノートブックで学習します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
