{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with TensorFlow\n",
    "\n",
    "**目的**\n",
    "  - Tensor の定義と基本的な演算の仕方を学ぶ\n",
    "  - `tf.function`の使い方とメリットを学ぶ\n",
    "  - Tensorflow の自動微分機能について学ぶ\n",
    "  - スクラッチで定義した線形回帰モデルのトレーニングの仕方を学ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックでは、TensorFlowでのTensorの演算と、TensoFlowでの変数の操作について学びます。また、Pythonのリスト型やnumpy arrayとの互換性についても確認します。\n",
    "\n",
    "その後で、簡単な線形回帰のモデルを、コアTensorFlowを使って（= Keras等のハイレベルAPIを使わずに）スクラッチで実装します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境の準備\n",
    "以下のコマンドを**一度だけ**実行し、その後**ノートブックのカーネルを再起動**してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一部エラーが出ても無視してかまいません\n",
    "!pip freeze | grep tensorflow==2.1 || pip install tensorflow==2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なパッケージのインストールとバージョンの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor の操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 変数(Variables) と定数(Constants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow上では、Tensorは定数 (`tf.constant`) か変数 (`tf.Variable`) のどちらかで定義されます。\n",
    "定数は一度定義すると変更できませんが、変数は値を自由に変更することができます。\n",
    "\n",
    "そのため、`tf.Variable`は値を変更するための様々なメソッドを持っていますが、`tf.constant`は持っていません。\n",
    "\n",
    "`tf.Variable` で定義された `x` を変更するためには、以下のようなメソッドを利用します。\n",
    "\n",
    "* `x.assign(new_value)`\n",
    "* `x.assign_add(value_to_be_added)`\n",
    "* `x.assign_sub(value_to_be_subtracted`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([2, 3, 4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(2.0, dtype=tf.float32, name='my_variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.assign(45.8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.assign_add(4).assign_sub(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 成分ごとの演算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow では、numpy のように成分毎に演算を適応することができます。\n",
    "\n",
    "* `tf.add`: 加算 \n",
    "* `tf.multiply`: 乗算\n",
    "* `tf.subtract`: 減算 \n",
    "* `tf.math.*`:  その他の様々な演算\n",
    "\n",
    "また、通常の演算子(`+`, `-`, etc.)を用いることでも、同様の結果を得ることができます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([5, 3, 8])\n",
    "b = tf.constant([3, -1, 2])\n",
    "c = tf.add(a, b)\n",
    "d = a + b\n",
    "\n",
    "print(\"c:\", c)\n",
    "print(\"d:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([5, 3, 8])\n",
    "b = tf.constant([3, -1, 2])\n",
    "c = tf.multiply(a, b)\n",
    "d = a * b\n",
    "\n",
    "print(\"c:\", c)\n",
    "print(\"d:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.math.exp expects floats so we need to explicitly give the type\n",
    "a = tf.constant([5, 3, 8], dtype=tf.float32)\n",
    "b = tf.math.exp(a)\n",
    "\n",
    "print(\"b:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python 型、NumPy との互換性\n",
    "\n",
    "TensorFlow のネイティブの Tensor 以外にも、Python の型や numpy array を演算に用いることもできます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# native python list\n",
    "a_py = [1, 2] \n",
    "b_py = [3, 4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.add(a_py, b_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy arrays\n",
    "a_np = np.array([1, 2])\n",
    "b_np = np.array([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.add(a_np, b_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# native TF tensor\n",
    "a_tf = tf.constant([1, 2])\n",
    "b_tf = tf.constant([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.add(a_tf, b_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、 `.numpy()` を利用して、TF Tensor を numpy array に変換することも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tf.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Functions\n",
    "\n",
    "関数を `tf.function` でアノテーションしても、他の関数と同様に扱うことができますが、その関数はグラフにコンパイルされて実行されます。\n",
    "そのため、高速な計算、GPU、TPUでの実行、SavedModel としてのエクスポートなどのメリットを得られます。\n",
    "\n",
    "複数のtf.functionを使用する場合、それぞれをアノテーションする必要はありません\n",
    "（アノテーションされた関数から呼び出された関数はグラフモードで実行されます）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def simple_nn_layer(x, y):\n",
    "  return tf.nn.relu(tf.matmul(x, y))\n",
    "\n",
    "x = tf.random.uniform((3, 3))\n",
    "y = tf.random.uniform((3, 3))\n",
    "\n",
    "simple_nn_layer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_layer(x):\n",
    "  return 2 * x + 1\n",
    "\n",
    "@tf.function\n",
    "def deep_net(x):\n",
    "  return tf.nn.relu(linear_layer(x))\n",
    "\n",
    "print(deep_net)\n",
    "deep_net(tf.constant((1, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "軽量の演算が大量に重ねられるようなグラフでは、`tf.function`で高速化することができますが、計算量の大きい演算が少数回行われるような演算では、大きな高速化は得られないかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "lstm_cell = tf.keras.layers.LSTMCell(10)\n",
    "\n",
    "@tf.function\n",
    "def lstm_fn(input, state):\n",
    "  return lstm_cell(input, state)\n",
    "\n",
    "input = tf.zeros([10, 10])\n",
    "state = [tf.zeros([10, 10])] * 2\n",
    "# warm up\n",
    "lstm_cell(input, state); lstm_fn(input, state)\n",
    "print(\"eager lstm:\", timeit.timeit(lambda: lstm_cell(input, state), number=100))\n",
    "print(\"function lstm:\", timeit.timeit(lambda: lstm_fn(input, state), number=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このケースでは、およそ1.5倍高速化されます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形回帰\n",
    "\n",
    "それでは、TensorFlow の低レベルAPIを使って、線形回帰のモデルを　実装してみましょう\n",
    "\n",
    "より抽象度の高い高レベルAPI (Keras) については、このコースの後半で学習します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トイデータセット\n",
    "\n",
    "では、以下の関数をモデル化しましょう。\n",
    "\n",
    "\\begin{equation}\n",
    "y= 2x + 10\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(range(10), dtype=tf.float32)\n",
    "Y = 2 * X + 10\n",
    "\n",
    "print(\"X:{}\".format(X))\n",
    "print(\"Y:{}\".format(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを検証するためのテストデータセットも作成しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tf.constant(range(10, 20), dtype=tf.float32)\n",
    "Y_test = 2 * X_test + 10\n",
    "\n",
    "print(\"X_test:{}\".format(X_test))\n",
    "print(\"Y_test:{}\".format(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 損失関数 (Loss Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$ から $Y$ を予測するための単純なモデルとして、$Y$の平均を返すだけのモデルを定義してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = Y.numpy().mean()\n",
    "\n",
    "def predict_mean(X):\n",
    "    y_hat = [y_mean] * len(X)\n",
    "    return y_hat\n",
    "\n",
    "Y_hat = predict_mean(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二乗誤差平均 (MSE, Mean Square Error)を使って、損失 (Loss) を計算してみましょう。\n",
    "\n",
    "\\begin{equation}\n",
    "MSE = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{Y}_i-Y_i)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この単純なモデルの損失は、以下のように計算できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (Y_hat - Y)**2\n",
    "loss = tf.reduce_mean(errors)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この MSE の値は、他のモデルのパフォーマンスと比較する際のベースラインとしておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{Y}$ を線形回帰モデルの予測とすると、\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{Y} = w_0X + w_1\n",
    "\\end{equation}\n",
    "\n",
    "引数にモデルの係数を取り、損失関数を以下のように書くこともできます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse(X, Y, w0, w1):\n",
    "    Y_hat = w0 * X + w1\n",
    "    errors = (Y_hat - Y)**2\n",
    "    return tf.reduce_mean(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 勾配の計算\n",
    "\n",
    "勾配降下法を使用するためには、それぞれの重み毎 ($w_0$ と $w_1$) に損失関数の偏微分を計算する必要があります。\n",
    "\n",
    "もちろん手動で行うこともできますが、Tensorflow には自動微分の機能が備わっているため、自分でコードを書く必要はありません！<br>\n",
    "この機能は、勾配の情報を保存する`tf.GradientTape`インスタンスの中で損失の計算を包み込むことで利用することができます。\n",
    "\n",
    "```python\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = # 損失の計算 \n",
    "```\n",
    "\n",
    "このようにすることで、 `tf.GradientTape` の中で計算されたすべてのTensorの勾配を後のステップでとして計算することができます。\n",
    "\n",
    "```python\n",
    "gradients = tape.gradient(loss, [w0, w1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X, Y, w0, w1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_mse(X, Y, w0, w1)\n",
    "    return tape.gradient(loss, [w0, w1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = tf.Variable(0.0)\n",
    "w1 = tf.Variable(0.0)\n",
    "\n",
    "dw0, dw1 = compute_gradients(X, Y, w0, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dw0:\", dw0.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dw1\", dw1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニングループ\n",
    "\n",
    "ここでは、ごくシンプルなトレーニングループを定義しましょうお。ミニバッチ、テストセットの分割、重みのランダムな初期化などのベストプラクティスは単純化のために一旦無視します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 1000\n",
    "LEARNING_RATE = .02\n",
    "MSG = \"STEP {step} - loss: {loss}, w0: {w0}, w1: {w1}\\n\"\n",
    "\n",
    "\n",
    "w0 = tf.Variable(0.0)\n",
    "w1 = tf.Variable(0.0)\n",
    "\n",
    "\n",
    "for step in range(0, STEPS + 1):\n",
    "\n",
    "    dw0, dw1 = compute_gradients(X, Y, w0, w1)\n",
    "    w0.assign_sub(dw0 * LEARNING_RATE)\n",
    "    w1.assign_sub(dw1 * LEARNING_RATE)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        loss = loss_mse(X, Y, w0, w1)\n",
    "        print(MSG.format(step=step, loss=loss, w0=w0.numpy(), w1=w1.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、この線形回帰モデルの損失と、常に平均値を返すだけのベースラインモデルの損失と比較してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_mse(X_test, Y_test, w0, w1)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以前のモデルよりずっとよくなりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
